# AI 提供商配置说明

## 支持的提供商

本工具支持两种 AI 提供商类型：

### 1. openai - OpenAI 兼容协议

使用 OpenAI Chat Completions API 标准协议，支持所有兼容该协议的服务：

- **OpenAI 官方**
  ```yaml
  ai:
    provider: "openai"
    api_key: "sk-..."
    base_url: "https://api.openai.com/v1"
    model: "gpt-4"
  ```

- **DeepSeek**
  ```yaml
  ai:
    provider: "openai"
    api_key: "sk-..."
    base_url: "https://api.deepseek.com/v1"
    model: "deepseek-coder"
  ```

- **通义千问（兼容模式）**
  ```yaml
  ai:
    provider: "openai"
    api_key: "sk-..."
    base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
    model: "qwen-coder-plus"
  ```

- **其他兼容服务**
  - Azure OpenAI
  - 本地部署的 LLM（如 Ollama、LocalAI）
  - 其他云服务商的兼容 API

### 2. dashscope - 阿里云 DashScope 应用模式

使用阿里云 DashScope 的应用级别 API：

```yaml
ai:
  provider: "dashscope"
  api_key: "sk-..."
  base_url: "https://dashscope.aliyuncs.com"  # 可选
  model: "YOUR_APP_ID"  # 应用 ID
```

**特点**：
- 使用应用 ID 而非模型名称
- 参数在 DashScope 控制台配置
- 支持自定义应用逻辑

## 配置参数说明

### 通用参数

| 参数 | 必填 | 说明 |
|------|------|------|
| provider | 是 | 提供商类型：openai 或 dashscope |
| api_key | 是 | API 密钥（支持加密） |
| model | 是 | 模型名称或应用 ID |

### OpenAI 协议专用参数

| 参数 | 必填 | 说明 |
|------|------|------|
| base_url | 是 | API 端点地址 |
| temperature | 否 | 温度参数（0-2），默认 0.3 |
| max_tokens | 否 | 最大令牌数，默认 3000 |

### DashScope 专用参数

| 参数 | 必填 | 说明 |
|------|------|------|
| base_url | 否 | API 地址，默认 https://dashscope.aliyuncs.com |

**注意**：DashScope 的 temperature 和 max_tokens 在应用配置中设置。

## 为什么简化提供商？

之前的版本支持 `openai`、`deepseek`、`custom` 三个提供商，但它们的实现逻辑完全相同，都使用 OpenAI Chat Completions API 协议。

**简化后的优势**：
1. **代码更简洁**：减少重复代码，便于维护
2. **配置更清晰**：通过 base_url 区分不同服务
3. **扩展性更好**：任何 OpenAI 兼容服务都可以使用
4. **向后兼容**：旧配置仍然可以工作（需要手动更新）

## 迁移指南

### 从 deepseek 迁移

**旧配置**：
```yaml
ai:
  provider: "deepseek"
  api_key: "sk-..."
  base_url: "https://api.deepseek.com/v1"
  model: "deepseek-coder"
```

**新配置**：
```yaml
ai:
  provider: "openai"  # 改为 openai
  api_key: "sk-..."
  base_url: "https://api.deepseek.com/v1"
  model: "deepseek-coder"
```

### 从 custom 迁移

**旧配置**：
```yaml
ai:
  provider: "custom"
  api_key: "sk-..."
  base_url: "https://your-api.com/v1"
  model: "your-model"
```

**新配置**：
```yaml
ai:
  provider: "openai"  # 改为 openai
  api_key: "sk-..."
  base_url: "https://your-api.com/v1"
  model: "your-model"
```

## 常见问题

### Q1: 为什么不保留 deepseek 提供商？

A: DeepSeek 完全兼容 OpenAI API 协议，使用 `provider: "openai"` 配合 DeepSeek 的 base_url 即可。保留单独的提供商会增加代码复杂度，但没有实际功能差异。

### Q2: 我的旧配置还能用吗？

A: 旧配置（provider: "deepseek" 或 "custom"）需要手动更新为 "openai"。程序会提示不支持的提供商。

### Q3: 如何使用本地部署的模型？

A: 使用 `provider: "openai"` 并配置本地服务的 base_url：
```yaml
ai:
  provider: "openai"
  api_key: "not-needed"  # 本地服务可能不需要
  base_url: "http://localhost:11434/v1"  # Ollama 示例
  model: "codellama"
```

### Q4: DashScope 的兼容模式和应用模式有什么区别？

A: 
- **兼容模式**：使用 OpenAI 协议，配置 `provider: "openai"` + 兼容模式 URL
- **应用模式**：使用 DashScope 专用协议，配置 `provider: "dashscope"` + 应用 ID

兼容模式更简单，应用模式支持更多自定义功能。

### Q5: 如何知道某个服务是否支持 OpenAI 协议？

A: 查看服务文档，如果支持 `/v1/chat/completions` 端点和 OpenAI 的请求/响应格式，就可以使用 `provider: "openai"`。

## 技术实现

### OpenAI 客户端

文件：`internal/ai/openai.go`

支持的 API 格式：
```json
POST {base_url}/chat/completions
{
  "model": "...",
  "messages": [
    {"role": "system", "content": "..."},
    {"role": "user", "content": "..."}
  ],
  "temperature": 0.3,
  "max_tokens": 3000
}
```

### DashScope 客户端

文件：`internal/ai/dashscope.go`

支持的 API 格式：
```json
POST {base_url}/api/v1/apps/{app_id}/completion
{
  "input": {
    "prompt": "..."
  },
  "parameters": {},
  "debug": {}
}
```

## 相关文档

- [config/README.md](./config/README.md) - 配置文件目录说明
- [DashScope集成说明.md](./DashScope集成说明.md) - DashScope 详细文档
- [config.example.yaml](./config.example.yaml) - 配置文件示例
